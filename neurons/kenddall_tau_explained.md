Excellent â€” this is a key concept for what youâ€™re doing (measuring rank stability).
Letâ€™s break Kendall distance (and Kendallâ€™s tau) down step by step.

â¸»

ğŸ§© Intuition

The Kendall distance measures how different two rankings are.

If you have two orderings of the same items (e.g. miners ranked by two different problem instances), Kendall distance counts how many pairwise order disagreements exist between them.

â¸»

ğŸ‘‡ Example

Suppose we have 4 miners: A, B, C, D.

Two rankings:

Miner	Ranking 1	Ranking 2
A	1	1
B	2	3
C	3	2
D	4	4

So:
	â€¢	Ranking 1: A > B > C > D
	â€¢	Ranking 2: A > C > B > D

Now look at all pairs of miners (there are \binom{4}{2} = 6 total pairs).

Pair	Ranking 1 order	Ranking 2 order	Agreement?
A,B	A > B	A > B	âœ…
A,C	A > C	A > C	âœ…
A,D	A > D	A > D	âœ…
B,C	B > C	C > B	âŒ
B,D	B > D	B > D	âœ…
C,D	C > D	C > D	âœ…

Thereâ€™s 1 discordant pair (B,C).

â¸»

ğŸ“ So the Kendall distance = number of discordant pairs = 1.

To normalize it (so itâ€™s between 0 and 1):

K = \frac{\text{discordant pairs}}{\text{total pairs}} = \frac{1}{6} \approx 0.167

â¸»

ğŸ” Relation to Kendallâ€™s Tau (Ï„)

Kendallâ€™s tau is just a normalized correlation version of this distance:

\tau = 1 - 2K = \frac{n_c - n_d}{\binom{n}{2}}
where:
	â€¢	n_c = number of concordant pairs,
	â€¢	n_d = number of discordant pairs.

So:
	â€¢	Ï„ = 1.0 â†’ rankings identical
	â€¢	Ï„ = 0.0 â†’ rankings random / uncorrelated
	â€¢	Ï„ = âˆ’1.0 â†’ rankings completely reversed

In our example:
\tau = 1 - 2 \times 0.167 = 0.667

â¸»

ğŸ§  Intuitive Meaning

Ï„ (or Kendall distance)	Interpretation
Ï„ â‰ˆ 1 (distance â‰ˆ 0)	Rankings nearly identical
Ï„ â‰ˆ 0.5	Mostly similar, a few swaps
Ï„ â‰ˆ 0	Unrelated or random rankings
Ï„ â‰ˆ âˆ’1 (distance â‰ˆ 1)	Rankings fully inverted


â¸»

ğŸ§® Implementation

You can compute Kendallâ€™s tau (and distance) easily in Python:

from scipy.stats import kendalltau
import numpy as np

r1 = [1, 2, 3, 4]  # ranking 1
r2 = [1, 3, 2, 4]  # ranking 2

tau, p_value = kendalltau(r1, r2)
kendall_distance = (1 - tau) / 2

print("tau =", tau)
print("distance =", kendall_distance)

Output:

tau = 0.6666...
distance = 0.1666...


â¸»

ğŸ”¬ Bittensor Miners

Kendall distance or Ï„ is used to measure how stable the miner rankings are from one round (problem) to another, e.g.:
	â€¢	If Ï„ is high (close to 1) between successive rounds, the rankings are stable.
	â€¢	If Ï„ keeps fluctuating or stays low, solvers are still producing inconsistent results.

So when you said earlier:

â€œI want to stop generating problems when variance in their rankings drops below a threshold,â€

you can equivalently say:

â€œI want to stop when the Kendall tau between successive rankings stays above 0.98 for several rounds.â€

â¸»

Would you like me to show how to compute Kendall distance between a current ranking and the cumulative historical mean ranking (like what youâ€™d use to detect convergence globally)?